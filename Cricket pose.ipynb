{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09584adc-dae7-42ff-9fa6-2efceaa6b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\ayush\\tf_env\\lib\\site-packages (15.0.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ayush\\tf_env\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\ayush\\tf_env\\lib\\site-packages (0.10.14)\n",
      "Requirement already satisfied: numpy in c:\\users\\ayush\\tf_env\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (2.3.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (3.10.5)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ayush\\tf_env\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from jax->mediapipe) (0.5.3)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\ayush\\tf_env\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from jax->mediapipe) (1.15.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ayush\\tf_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytube opencv-python mediapipe numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376d7b46-b341-4c98-a9de-2364e3da0efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processing complete!\n",
      "Annotated video saved at: output\\annotated_video.mp4\n",
      "Evaluation JSON saved at: output\\evaluation.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import yt_dlp\n",
    "import math\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "\n",
    "# 1) Configurations\n",
    "\n",
    "VIDEO_URL = \"https://www.youtube.com/shorts/vSX3IRxGnNY\"\n",
    "VIDEO_PATH = \"input_video.mp4\"\n",
    "OUTPUT_DIR = \"output\"\n",
    "OUTPUT_VIDEO_PATH = os.path.join(OUTPUT_DIR, \"annotated_video.mp4\")\n",
    "EVALUATION_JSON = os.path.join(OUTPUT_DIR, \"evaluation.json\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# 2) Download YouTube video \n",
    "\n",
    "if not os.path.exists(VIDEO_PATH):\n",
    "    print(\"[INFO] Downloading video from YouTube...\")\n",
    "    ydl_opts = {'format': 'best', 'outtmpl': VIDEO_PATH}\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([VIDEO_URL])\n",
    "    print(\"[INFO] Download complete!\")\n",
    "\n",
    "\n",
    "# 3) Setup MediaPipe \n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5,\n",
    "                    min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "# 4) Thresholds\n",
    "\n",
    "THRESH = {\n",
    "    \"elbow_good_min\": 120.0,\n",
    "    \"elbow_good_max\": 175.0,\n",
    "    \"spine_good_min\": 5.0,\n",
    "    \"spine_good_max\": 25.0,\n",
    "    \"head_knee_max_gap_frac\": 0.06,\n",
    "    \"foot_angle_max_abs\": 25.0,\n",
    "    \"visibility_thresh\": 0.4,\n",
    "    \"ema_alpha\": 0.18,\n",
    "}\n",
    "\n",
    "\n",
    "# 5) Helper functions\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle at point b formed by points a-b-c in degrees.\"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a-b, c-b\n",
    "    cos_angle = np.dot(ba, bc) / (np.linalg.norm(ba)*np.linalg.norm(bc)+1e-8)\n",
    "    return np.degrees(np.arccos(np.clip(cos_angle, -1.0, 1.0)))\n",
    "\n",
    "def get_coords(landmarks, idx, width, height):\n",
    "    \"\"\"Get pixel coordinates from landmark index.\"\"\"\n",
    "    return [landmarks[idx].x * width, landmarks[idx].y * height]\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Angle between two vectors.\"\"\"\n",
    "    v1, v2 = np.array(v1), np.array(v2)\n",
    "    norm1, norm2 = np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "    if norm1<1e-8 or norm2<1e-8: return 0\n",
    "    cos = np.clip(np.dot(v1,v2)/(norm1*norm2), -1, 1)\n",
    "    return math.degrees(math.acos(cos))\n",
    "\n",
    "def safe_div(a,b):\n",
    "    return a/b if b!=0 else 0\n",
    "\n",
    "def score_from_ratio(ratio):\n",
    "    \"\"\"Convert 0-1 ratio to 1-10 score (nonlinear).\"\"\"\n",
    "    ratio = max(0.0, min(1.0, ratio))\n",
    "    return int(round(1 + 9*(ratio**0.85)))\n",
    "\n",
    "\n",
    "# 6) Open video\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"[ERROR] Cannot open video file.\")\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "# 7) Frame processing variables\n",
    "\n",
    "metrics_history = []\n",
    "ema_state = {\"elbow\": None, \"spine\": None, \"head_knee\": None, \"foot\": None}\n",
    "prev_elbow = None\n",
    "alpha = THRESH[\"ema_alpha\"]\n",
    "frame_idx = 0\n",
    "t_start = time.time()\n",
    "elbow_history = deque(maxlen=100)  # for rolling plot\n",
    "\n",
    "#\n",
    "# 8) Main frame looop\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_idx += 1\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "    display_frame = frame.copy()\n",
    "    frame_metrics = {}\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        lms = results.pose_landmarks.landmark\n",
    "        # ---- Keypoints ----\n",
    "        l_shoulder = get_coords(lms, mp_pose.PoseLandmark.LEFT_SHOULDER.value, width, height)\n",
    "        l_elbow = get_coords(lms, mp_pose.PoseLandmark.LEFT_ELBOW.value, width, height)\n",
    "        l_wrist = get_coords(lms, mp_pose.PoseLandmark.LEFT_WRIST.value, width, height)\n",
    "        l_hip = get_coords(lms, mp_pose.PoseLandmark.LEFT_HIP.value, width, height)\n",
    "        l_knee = get_coords(lms, mp_pose.PoseLandmark.LEFT_KNEE.value, width, height)\n",
    "        l_heel = get_coords(lms, mp_pose.PoseLandmark.LEFT_HEEL.value, width, height)\n",
    "        l_foot = get_coords(lms, mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value, width, height)\n",
    "        nose = get_coords(lms, mp_pose.PoseLandmark.NOSE.value, width, height)\n",
    "\n",
    "        # ---- Matrics calculation ----\n",
    "        elbow_angle = calculate_angle(l_shoulder,l_elbow,l_wrist)\n",
    "        spine_lean = angle_between([l_shoulder[0]-l_hip[0], l_shoulder[1]-l_hip[1]], [0,-1])\n",
    "        head_knee_gap_frac = safe_div(abs(nose[0]-l_knee[0]), width)\n",
    "        foot_vec = [l_foot[0]-l_heel[0], l_foot[1]-l_heel[1]]\n",
    "        foot_angle = angle_between(foot_vec,[1,0])\n",
    "        cross_z = foot_vec[0]*0.0 - foot_vec[1]*1.0\n",
    "        foot_angle = -foot_angle if cross_z<0 else foot_angle\n",
    "\n",
    "        frame_metrics.update({\"elbow\": elbow_angle, \"spine\": spine_lean,\n",
    "                              \"head_knee\": head_knee_gap_frac, \"foot\": foot_angle})\n",
    "\n",
    "        # ---- EMA smoothing ----\n",
    "        display_vals = {}\n",
    "        for k,v in frame_metrics.items():\n",
    "            if ema_state[k] is None:\n",
    "                ema_state[k] = v\n",
    "            else:\n",
    "                ema_state[k] = alpha*v + (1-alpha)*ema_state[k]\n",
    "            display_vals[k] = ema_state[k]\n",
    "\n",
    "        # ---- Overlay metrics ----\n",
    "        y0, dy = 30, 30\n",
    "        cv2.putText(display_frame, f\"Elbow: {display_vals['elbow']:.1f}°\", (10,y0),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)\n",
    "        cv2.putText(display_frame, f\"Spine: {display_vals['spine']:.1f}°\", (10,y0+dy),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)\n",
    "        cv2.putText(display_frame, f\"Head-Knee: {display_vals['head_knee']*100:.1f}%W\", (10,y0+2*dy),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)\n",
    "        cv2.putText(display_frame, f\"Front Foot: {display_vals['foot']:.1f}°\", (10,y0+3*dy),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)\n",
    "\n",
    "        # ---- Short feedback ----\n",
    "        fb = []\n",
    "        fb.append(\"✅ Good elbow\" if THRESH[\"elbow_good_min\"]<elbow_angle<THRESH[\"elbow_good_max\"] else \"❌ Adjust elbow\")\n",
    "        fb.append(\"✅ Spine balanced\" if THRESH[\"spine_good_min\"]<spine_lean<THRESH[\"spine_good_max\"] else \"❌ Spine lean off\")\n",
    "        fb.append(\"✅ Head over knee\" if head_knee_gap_frac<THRESH[\"head_knee_max_gap_frac\"] else \"❌ Head too far forward\")\n",
    "        fb.append(\"✅ Foot aligned\" if abs(foot_angle)<THRESH[\"foot_angle_max_abs\"] else \"❌ Foot misaligned\")\n",
    "\n",
    "        for i,f in enumerate(fb):\n",
    "            color = (0,200,0) if f.startswith(\"✅\") else (0,0,255)\n",
    "            cv2.putText(display_frame,f,(10,y0+5*dy+i*dy),cv2.FONT_HERSHEY_SIMPLEX,0.7,color,2)\n",
    "\n",
    "      \n",
    "        mp_drawing.draw_landmarks(display_frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=3),\n",
    "                                  connection_drawing_spec=mp_drawing.DrawingSpec(color=(255,0,0), thickness=2))\n",
    "\n",
    "  \n",
    "        if prev_elbow is not None:\n",
    "            frame_metrics['elbow_smooth'] = abs(elbow_angle-prev_elbow)\n",
    "        prev_elbow = elbow_angle\n",
    "        elbow_history.append(elbow_angle)\n",
    "\n",
    "       \n",
    "        plot_h, plot_w = 50, width\n",
    "        plot_img = np.zeros((plot_h,plot_w,3), dtype=np.uint8)\n",
    "        for idx,val in enumerate(elbow_history):\n",
    "            x = int(idx*plot_w/len(elbow_history))\n",
    "            y = int(plot_h - (val/180)*plot_h)\n",
    "            cv2.circle(plot_img,(x,y),1,(0,255,255),-1)\n",
    "        display_frame[-plot_h:,-plot_w:] = plot_img\n",
    "\n",
    "    metrics_history.append(frame_metrics)\n",
    "\n",
    "    # ---- FPS display ----\n",
    "    elapsed = time.time()-t_start\n",
    "    fps_est = frame_idx/elapsed if elapsed>0 else 0\n",
    "    cv2.putText(display_frame,f\"FPS: {fps_est:.1f}\",(width-150,30),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),2)\n",
    "\n",
    "    out.write(display_frame)\n",
    "    cv2.imshow(\"Cricket Cover Drive Analysis\", display_frame)\n",
    "    if cv2.waitKey(1) & 0xFF==27:  # ESC to quit\n",
    "        break\n",
    "\n",
    "\n",
    "# 9) Release \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "pose.close()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# -----------------------\n",
    "# 10) Aggregate scores\n",
    "# -----------------------\n",
    "n_frames = max(1,len(metrics_history))\n",
    "elbow_ok = sum(1 for m in metrics_history if 'elbow' in m and THRESH[\"elbow_good_min\"]<=m['elbow']<=THRESH[\"elbow_good_max\"])\n",
    "spine_ok = sum(1 for m in metrics_history if 'spine' in m and THRESH[\"spine_good_min\"]<=m['spine']<=THRESH[\"spine_good_max\"])\n",
    "head_ok = sum(1 for m in metrics_history if 'head_knee' in m and m['head_knee']<THRESH[\"head_knee_max_gap_frac\"])\n",
    "foot_ok = sum(1 for m in metrics_history if 'foot' in m and abs(m['foot'])<THRESH[\"foot_angle_max_abs\"])\n",
    "elbow_diffs = [m.get('elbow_smooth',0) for m in metrics_history if 'elbow_smooth' in m]\n",
    "smooth_factor = 1.0 - np.mean(elbow_diffs)/40.0 if elbow_diffs else 0.5\n",
    "smooth_factor = min(max(smooth_factor,0),1)\n",
    "\n",
    "scores = {\n",
    "    \"Footwork\": score_from_ratio(foot_ok/n_frames),\n",
    "    \"Head Position\": score_from_ratio(head_ok/n_frames),\n",
    "    \"Swing Control\": score_from_ratio(smooth_factor),\n",
    "    \"Balance\": score_from_ratio(0.5*spine_ok/n_frames + 0.5*head_ok/n_frames),\n",
    "    \"Follow-through\": score_from_ratio(0.5*elbow_ok/n_frames + 0.5*spine_ok/n_frames),\n",
    "}\n",
    "\n",
    "comments = {\n",
    "    \"Footwork\": \"Good alignment when foot_angle within range.\" if foot_ok/n_frames>0.6 else \"Work on front foot aiming; reduce toe-out.\",\n",
    "    \"Head Position\": \"Head consistently over front knee.\" if head_ok/n_frames>0.6 else \"Keep head stacked over front knee.\",\n",
    "    \"Swing Control\": \"Smooth elbow motion.\" if np.mean(elbow_diffs)<12 else \"Reduce abrupt elbow changes.\",\n",
    "    \"Balance\": \"Stable posture and spine lean.\" if spine_ok/n_frames>0.6 else \"Maintain slight forward lean (5–25°).\",\n",
    "    \"Follow-through\": \"Good continuation of swing.\" if (0.5*elbow_ok/n_frames + 0.5*spine_ok/n_frames)>0.6 else \"Complete follow-through with tall posture.\",\n",
    "}\n",
    "\n",
    "evaluation = {\n",
    "    \"video\": os.path.abspath(VIDEO_PATH),\n",
    "    \"frames\": n_frames,\n",
    "    \"avg_fps\": round(fps_est,2),\n",
    "    \"scores\": scores,\n",
    "    \"comments\": comments,\n",
    "    \"thresholds\": THRESH\n",
    "}\n",
    "\n",
    "with open(EVALUATION_JSON,'w') as f:\n",
    "    json.dump(evaluation,f,indent=2)\n",
    "\n",
    "print(\"✅ Processing complete!\")\n",
    "print(f\"Annotated video saved at: {OUTPUT_VIDEO_PATH}\")\n",
    "print(f\"Evaluation JSON saved at: {EVALUATION_JSON}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff1034-ec50-4558-bddd-4528d03bd861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
